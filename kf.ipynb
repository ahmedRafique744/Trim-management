{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "64accec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    " \n",
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11417b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = ''\n",
    "gps_gf = np.load(file_path)\n",
    "print('gps data shape: ', gps_gf.shape)\n",
    "\n",
    "gps_df = pd.DataFrame(gps_gf[1:,:], columns=gps_gf[0,:])\n",
    "cols_to_convert = gps_df.columns[gps_df.columns != 'interval_id']\n",
    "gps_df[cols_to_convert] = gps_df[cols_to_convert].apply(pd.to_numeric, errors='coerce') \n",
    "\n",
    "gps_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12132572",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotation_ned(lat, lon):\n",
    "    R_ned = np.array([[-np.sin(lat)*np.cos(lon), -np.sin(lat)*np.sin(lon), np.cos(lat)],\n",
    "                     [-np.sin(lon), np.cos(lon),0],\n",
    "                     [-np.cos(lat)*np.cos(lon), -np.cos(lat)*np.sin(lon), -np.sin(lat)]])\n",
    "    return R_ned \n",
    "def gps_pos_vel(gps_ned, dt): \n",
    "\n",
    "    vel_ned = gps_ned / dt.values[:, np.newaxis]\n",
    "    acc_ned = np.diff(vel_ned, axis=0) / dt.values[1:, np.newaxis]  \n",
    "    displacement = np.cumsum(gps_ned, axis=0)\n",
    "    return vel_ned, acc_ned, displacement\n",
    "\n",
    "def ecef_to_ned(gps_pos_ref):\n",
    "    deltas = (gps_pos_ref[['Node[1].ECEF.X', 'Node[1].ECEF.Y', 'Node[1].ECEF.Z']].values /1000) - (gps_pos_ref[['Node[1].ECEF.X.ref', 'Node[1].ECEF.Y.ref', 'Node[1].ECEF.Z.ref']].values/1000)   \n",
    "    \n",
    "    #use reference lat and lon points \n",
    "    lons = gps_pos_ref['Node[1].LLH.Lon.ref'] * (np.pi/180) \n",
    "    lats = gps_pos_ref['Node[1].LLH.Lat.ref'] * (np.pi/180)\n",
    "\n",
    "    ned_values = []\n",
    "    mags = []\n",
    "    timestamps = []\n",
    "    for i, (lat, lon) in enumerate(zip(lats, lons)): \n",
    "        rotation_matrix = rotation_ned(lat,lon)\n",
    "        norm = np.linalg.norm(deltas[i,:])\n",
    "        ned_vec = rotation_matrix @ deltas[i,:] / norm\n",
    "        ned_mag = np.linalg.norm(ned_vec)\n",
    "        mags.append(ned_mag )\n",
    "        ned_values.append(ned_vec * norm)\n",
    "        timestamps.append(gps_pos_ref.iloc[i]['timestamp'])\n",
    "    ned_values = np.array(ned_values)\n",
    "    return ned_values, np.array(mags), np.array(timestamps)\n",
    "\n",
    "new_gps = gps_df.copy()\n",
    "new_gps[['Node[1].ECEF.X.ref','Node[1].ECEF.Y.ref', 'Node[1].ECEF.Z.ref',\n",
    "         'Node[1].LLH.Lat.ref','Node[1].LLH.Lon.ref','timestamp_ref']] = new_gps[[\"Node[1].ECEF.X\", \"Node[1].ECEF.Y\",\n",
    "                                                                                  \"Node[1].ECEF.Z\",'Node[1].LLH.Lat',\n",
    "                                                                                  'Node[1].LLH.Lon', 'timestamp']].shift(1)\n",
    "\n",
    "gps_pos_ref = new_gps[[\"Node[1].ECEF.X\", \"Node[1].ECEF.Y\",\n",
    "                       \"Node[1].ECEF.Z\",'Node[1].ECEF.X.ref',\n",
    "                       'Node[1].ECEF.Y.ref', 'Node[1].ECEF.Z.ref',\n",
    "                      'Node[1].LLH.Lat.ref', 'Node[1].LLH.Lon.ref',\n",
    "                      'timestamp','timestamp_ref','interval_id']].dropna()\n",
    "\n",
    "gps_ned, ned_mags, timestamps = ecef_to_ned(gps_pos_ref) \n",
    "print(gps_ned.shape, timestamps.shape)\n",
    "\n",
    "dt = gps_pos_ref['timestamp'] - gps_pos_ref['timestamp_ref']\n",
    "vel_ned, acc_ned, displacement = gps_pos_vel(gps_ned, dt)\n",
    "print(vel_ned.shape, acc_ned.shape, displacement.shape)\n",
    "gps_vel_pos = np.column_stack([vel_ned, displacement, timestamps])\n",
    "\n",
    "gps_vel_pos_df = pd.DataFrame(gps_vel_pos, columns=['vel.x', 'vel.y', 'vel.z', 'pos.x', 'pos.y', 'pos.z', 'timestamp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d26850a",
   "metadata": {},
   "outputs": [],
   "source": [
    "xl_global = pd.read_csv(r\"C:\\Users\\johncmarkowicz\\BaseStation\\AI\\notebooks\\ai_models\\ai_models_data\\node1_global_xl_combined.npy\")\n",
    "xl_global.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72457b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_ts_col = []\n",
    "curr_ts = 0\n",
    "dt = 1/1000\n",
    "curr_int = 0\n",
    "for _, row in xl_global.iterrows():\n",
    "    if curr_ts == 0:\n",
    "        curr_ts = float(int(row['timestamp']))\n",
    "        curr_int = int(row['timestamp'])\n",
    "        new_ts_col.append(curr_ts)\n",
    "\n",
    "    else:\n",
    "        if curr_int != int(row['timestamp']):\n",
    "            if int(row['timestamp']) - curr_int > 1:\n",
    "                new_ts = round(new_ts_col[-1] + 1 + dt, 3)\n",
    "                new_ts_col.append(new_ts)\n",
    "            else:    \n",
    "                new_ts = round(new_ts_col[-1] + dt, 3)\n",
    "                new_ts_col.append(new_ts)\n",
    "            \n",
    "            curr_int = int(row['timestamp'])\n",
    "            continue\n",
    "\n",
    "        new_ts = round(new_ts_col[-1] + dt, 3)\n",
    "        new_ts_col.append(new_ts)\n",
    "\n",
    "xl_global['timestamp_aligned'] = pd.Series(new_ts_col)\n",
    "xl_global['timestamp_aligned'].head()\n",
    "\n",
    "np.unique(np.diff(xl_global['timestamp'].astype(int)), return_counts=True) # when dt is 2, this indicates missing interval "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77b8c8cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_acc(row):\n",
    "    acc = np.sqrt(row['x']**2 + row['y']**2)\n",
    "    if row['x'] < 0:\n",
    "        acc*=-1\n",
    "    else:\n",
    "        acc = np.abs(acc)\n",
    "    return acc\n",
    "\n",
    "def xl_state_estimate(x_prev, u, F, dt):\n",
    "    x_k = F @ np.array(x_prev) + np.array([(dt**2)/2, dt]) * u \n",
    "                   \n",
    "    return x_k \n",
    "\n",
    "\n",
    "def Kalman_acc_update(x_prev, P_prev, Q_xl, F, row, imu_dt):\n",
    "\n",
    "    acc = get_acc(row)\n",
    "    x_update = xl_state_estimate(x_prev, acc, F, imu_dt)\n",
    "    P_update = F @ P_prev @ F.T + Q_xl\n",
    "\n",
    "    return x_update, P_update\n",
    "\n",
    "\n",
    "def Kalman_gps_udpate(gps_state, P_prev, x_prev, Q_gps):\n",
    "    \n",
    "    K = P_prev @ np.linalg.inv(P_prev + Q_gps)\n",
    "    H = np.array([[1, 0], [0, 1]])  #\n",
    "    # print(\"GPS STATE,XPREV\",gps_state, x_prev)\n",
    "    # print(\"GAIN \", K)\n",
    "    # print(\"Kalman Resiudal\",  K @ (gps_state - x_prev))\n",
    "    # print(\"RESIDUAL: \", gps_state - x_prev)\n",
    "    # print(\"GPS STATE\", gps_state)\n",
    "    x_update = x_prev + K @ (gps_state - x_prev)\n",
    "    # P_update = P_prev - K @ Q_gps\n",
    "    P_update = (np.eye(2) - K @ H) @ P_prev\n",
    "\n",
    "    # print(\"GPS UPDATE\", x_update)\n",
    "    return x_update, P_update, K\n",
    "\n",
    "def test_kalman(xl_global, gps_df, init_x, gps_dt):\n",
    "    \n",
    "    gps_idx = 0 \n",
    "    x_history = [init_x]\n",
    "    P_history = [Q_xl]\n",
    "    gain_history = []\n",
    "\n",
    "    F = np.array([[1, .001],[0, 1]]) \n",
    "\n",
    "    for i, row in xl_global.iterrows():\n",
    "\n",
    "        if i == 0:\n",
    "            imu_dt = .001\n",
    "            gps_dt = .2\n",
    "\n",
    "        else: \n",
    "            imu_dt = xl_global.iloc[i]['timestamp_aligned'] - xl_global.iloc[i-1]['timestamp_aligned']\n",
    "            gps_dt = gps_df.iloc[gps_idx]['timestamp'] - gps_df.iloc[gps_idx-1]['timestamp']\n",
    "\n",
    "\n",
    "        spectral_density_variance = 0.17527 # after 1 hour \n",
    "        velocity_random_walk_variance_xy =  0.0053 # after 1 hour \n",
    "\n",
    "        Q_xl = spectral_density_variance * np.array([\n",
    "                [imu_dt**4 / 4, imu_dt**3 / 2],\n",
    "                [imu_dt**3 / 2, imu_dt**2]\n",
    "            ]) + velocity_random_walk_variance_xy * np.array([\n",
    "                [0, 0],\n",
    "                [0, 1]\n",
    "            ])\n",
    "\n",
    "        gps_vel_var = (0.125 * 5) * gps_dt\n",
    "        gps_pos_var = (gps_vel_var * 5) * gps_dt**2\n",
    "\n",
    "        R_gps = np.array([[gps_pos_var,0],[0, gps_vel_var]]) \n",
    "\n",
    "        xl_ts = row['timestamp_aligned']\n",
    "        match = gps_df[gps_df['timestamp'] == xl_ts]\n",
    "                    \n",
    "        x_k, P_k = Kalman_acc_update(x_history[-1], P_history[-1], Q_xl, F, row, imu_dt)\n",
    "        # print(\"X_K\", x_k)\n",
    "\n",
    "        if not match.empty and xl_ts != 46757790.0:\n",
    "            gps_idx += 1\n",
    "            vel_xyz = match[['vel.x', 'vel.y']]\n",
    "            pos_xyz = match[['pos.x', 'pos.y']]\n",
    "            gps_vel = np.linalg.norm(vel_xyz, axis=1)\n",
    "            gps_pos = np.linalg.norm(pos_xyz, axis=1)\n",
    "            gps_state = np.array([gps_pos[0], gps_vel[0]])\n",
    "            # print(\"GPS STATE,XPREV\",gps_state,  x_history[-1])\n",
    "\n",
    "            x_update, P_update, gain = Kalman_gps_udpate(gps_state, P_k, x_k, R_gps)\n",
    "\n",
    "            x_history.append(x_update)\n",
    "            P_history.append(P_update)\n",
    "            gain_history.append(gain)\n",
    "\n",
    "        else:\n",
    "            x_history.append(x_k)\n",
    "            P_history.append(P_k)\n",
    "\n",
    "    return np.array(x_history), np.array(P_history), gain_history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f37fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "inital_pos = np.linalg.norm([-20.153199, 36.532236]) # these come from getting the first xl and gps shared timestamp \n",
    "inital_vel = np.linalg.norm([-6.823665, 12.101643])\n",
    "init_x = np.array([inital_pos, inital_vel])\n",
    "\n",
    "x_history, P_history, gain_history = test_kalman(xl_global.iloc[:], gps_vel_pos_df.iloc[:], init_x, gps_dt=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27869cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_hist = np.array(P_history)\n",
    "cov_00 = []\n",
    "cov_01 = []\n",
    "\n",
    "cov_11= []\n",
    "cov_10= []\n",
    "\n",
    "for p in p_hist:\n",
    "    cov_00.append(p[0,0])\n",
    "    cov_01.append(p[0,1])\n",
    "\n",
    "    cov_11.append(p[1,1])\n",
    "    cov_10.append(p[0,1])\n",
    "\n",
    "plt.plot(cov_00)\n",
    "plt.show()\n",
    "\n",
    "plt.plot(cov_01)\n",
    "plt.show()\n",
    "\n",
    "plt.plot(cov_10)\n",
    "plt.show()\n",
    "\n",
    "plt.plot(cov_11)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.plot(x_history[:,0])\n",
    "plt.title('Position')\n",
    "plt.show()\n",
    "plt.plot(x_history[:,1])\n",
    "plt.title('Velocity')\n",
    "plt.show()\n",
    "\n",
    "gain_0 = []\n",
    "gain_1 = []\n",
    "for k in gain_history:\n",
    "    gain_0.append(k[0,0])\n",
    "    gain_1.append(k[1,1])\n",
    "\n",
    "plt.plot(gain_0)\n",
    "plt.title('Kalman Gain')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(gain_1)\n",
    "plt.title('Kalman Gain')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

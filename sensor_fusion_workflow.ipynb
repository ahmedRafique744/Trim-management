{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34189fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def preprocess_sensor(dat):\n",
    "    \"\"\" \n",
    "    Sorts sensor data by timestamp and removes duplicates\n",
    "    Params: \n",
    "        dat: sensor data \n",
    "    \"\"\"\n",
    "\n",
    "    dat = np.array(dat).astype(float)\n",
    "    sorted_dat = dat[dat[:,0].argsort()]\n",
    "\n",
    "    _, unique_indices = np.unique(sorted_dat[:,0], return_index = True)\n",
    "    processed_data = sorted_dat[unique_indices]\n",
    "    return processed_data\n",
    "\n",
    "def clip_xl(xl_dat, clip):\n",
    "    \"\"\"\n",
    "    XL sensors above certain thresholds are defective\n",
    "    \"\"\"\n",
    "    xl_clipped = np.where(xl_dat > clip, clip, xl_dat)\n",
    "    xl_clipped = np.where(xl_clipped < -1*clip, -1*clip, xl_clipped)\n",
    "    return xl_clipped\n",
    "\n",
    "def preprocess_imu(xl_raw, gyr_raw, gyr_offset):\n",
    "    \"\"\"\n",
    "    correct units, remove gyr offset\n",
    "    Returns:\n",
    "        data_matrix: (xl, mag, gyr)\n",
    "    \"\"\"\n",
    "\n",
    "    xl = xl_raw * 9.810665\n",
    "    gyr = gyr_offset_radians(gyr_raw, gyr_offset)\n",
    "    return xl, gyr\n",
    "\n",
    "def gyr_offset_radians(gyr_dat, offset):\n",
    "    \"\"\"Put gy data in radians, remove measured error \"\"\"\n",
    "    gyr_off = gyr_dat - offset\n",
    "    gyro_rad = gyr_off * ( np.pi / 180)\n",
    "    return gyro_rad\n",
    "\n",
    "def time_align(xyz, sensor_odr, interval_odr):\n",
    "    \"\"\" \n",
    "    Upsample data 2x interval odr(fourier signal), decimate data back down(lowpass filter), interpolate to desired odr, select current interval points\n",
    "    \"\"\"\n",
    "    xyz_w = []\n",
    "    len_w = []\n",
    "    for i, ts in enumerate(xyz):\n",
    "        xyz_w.append(ts)\n",
    "        len_w.append(len(ts))\n",
    "\n",
    "    xyz_w = np.vstack(xyz_w)\n",
    "    # if name == 'xl':\n",
    "        # print('raw',xyz_w.shape)\n",
    "\n",
    "    xyz_r = resample(xyz_w, num=(sensor_odr*3)*2, axis=0)\n",
    "    factor = xyz_r.shape[0]//((sensor_odr*3))\n",
    "    xyz_d = decimate(xyz_r, q=factor, axis=0)\n",
    "\n",
    "    current_points = xyz_d[interval_odr:interval_odr*2]\n",
    "    \n",
    "    # print('final', np.array(current_points).shape)\n",
    "    return np.array(current_points)\n",
    "\n",
    "def normalize(q): \n",
    "    #norm = np.sqrt(q @ q.T)\n",
    "    norm = magnitude(q)\n",
    "    return q/norm \n",
    "\n",
    "def quatConjugate(q):\n",
    "        w,x,y,z = q\n",
    "        q_star = np.array([w,-x,-y,-z])\n",
    "        return q_star\n",
    "        \n",
    "def quatProduct(q, p):\n",
    "        q = np.array(q)\n",
    "        p = np.array(p)\n",
    "        w, x, y, z = list(q)\n",
    "\n",
    "        q_matrix = np.array([\n",
    "            [w, -x, -y, -z],\n",
    "            [x, w, -z, y],\n",
    "            [y, z, w, -x],\n",
    "            [z, -y, x, w]\n",
    "        ])\n",
    "        return q_matrix @ p\n",
    "\n",
    "def inverse(q):\n",
    "    q_star = quatConjugate(q)\n",
    "    mag = magnitude(q)\n",
    "    if  0.998 < mag < 1.001:\n",
    "        return q_star\n",
    "    else:\n",
    "        q_inverse = q_star / mag**2\n",
    "        return q_inverse\n",
    "    \n",
    "def magnitude(q):\n",
    "    return np.sqrt(q[0]**2 + q[1]**2 + q[2]**2 + q[3]**2)\n",
    "\n",
    "def rotate_vector(q, v, active=True):\n",
    "    v = np.insert(np.array(v), 0, 0)  # convert to pure quaternion\n",
    "    q_inv = inverse(q)\n",
    "\n",
    "    if active: # object rotation\n",
    "        q_product = quatProduct(q, v)\n",
    "        q_rot = quatProduct(q_product, q_inv)\n",
    "    else: # coordinate rotation\n",
    "        q_product = quatProduct(q_inv, v)\n",
    "        q_rot = quatProduct(q_product, q)\n",
    "\n",
    "    return q_rot[1:]\n",
    "\n",
    "def R(q_w, q_x, q_y, q_z):\n",
    "    \"\"\"\n",
    "    Direction Cosine Matrix to rotate between two frames\n",
    "    \"\"\"\n",
    "    # rotation_matrix = np.array([\n",
    "    #     [q_w**2+q_x**2-q_y**2-q_z**2, 2*(q_x*q_y-q_w*q_z), 2*(q_x*q_z+q_w*q_y)],\n",
    "    #     [2*(q_x*q_y+q_w*q_z), q_w**2-q_x**2+q_y**2-q_z**2, 2*(q_y*q_z-q_w*q_x)],\n",
    "    #     [2*(q_x*q_z-q_w*q_y), 2*(q_w*q_x+q_y*q_z), q_w**2-q_x**2-q_y**2+q_z**2]\n",
    "    # ])\n",
    "            \n",
    "    rotation_matrix = np.array([\n",
    "        [1.0-2.0*(q_y**2+q_z**2), 2.0*(q_x*q_y-q_w*q_z), 2.0*(q_x*q_z+q_w*q_y)],\n",
    "        [2.0*(q_x*q_y+q_w*q_z), 1.0-2.0*(q_x**2+q_z**2), 2.0*(q_y*q_z-q_w*q_x)],\n",
    "        [2.0*(q_x*q_z-q_w*q_y), 2.0*(q_w*q_x+q_y*q_z), 1.0-2.0*(q_x**2+q_y**2)]\n",
    "        ])\n",
    "    return rotation_matrix\n",
    "\n",
    "def rotate_to_ned(q,vec):\n",
    "    \"\"\"\n",
    "    rotates raw data by quaternion into global frame\n",
    "    \"\"\"\n",
    "    rotation_matrix = R(*q)\n",
    "    global_estimate = rotation_matrix.T @ vec  #eq. 10 \n",
    "    \n",
    "    return global_estimate\n",
    "\n",
    "def quaternion_to_euler(q_L_G):\n",
    "    \"\"\"Calculate yaw pitch and roll from quaterion\n",
    "    Args:\n",
    "        q_L_G: quaternion representing rotation from local to NED frame \n",
    "    Returns:\n",
    "        yaw, pitch, roll in numpy arrays\n",
    "    \"\"\"\n",
    "    yaws, pitches, rolls = [], [], []\n",
    "    for q in q_L_G:\n",
    "\n",
    "        w, x, y, z = q\n",
    "        roll = math.atan2(2*(w*x + y*z), 1 - 2*(x**2 + y**2))\n",
    "        pitch = -np.pi + 2*(math.atan2(np.sqrt(1+2*(w*y-x*z)),np.sqrt(1-2*(w*y-x*z))))\n",
    "        yaw = math.atan2(2*(w*z + x*y), 1 - 2*(y**2 + z**2))\n",
    "        yaw, pitch, roll = np.degrees(yaw), np.degrees(pitch), np.degrees(roll)\n",
    "\n",
    "        yaws.append(yaw)\n",
    "        rolls.append(roll)\n",
    "        pitches.append(pitch)\n",
    "    yaws = np.array(yaws) % 360\n",
    "\n",
    "    return yaws, np.array(pitches), np.array(rolls)\n",
    "\n",
    "def align_timestamps(xl, gy, interval_odr, gyr_offset):\n",
    "    cols =['interval','timestamp','x', 'y', 'z']\n",
    "\n",
    "    xl_df = pd.DataFrame(xl, columns=cols)\n",
    "    xl_df = xl_df.astype({'x': float, 'y': float, 'z': float, 'timestamp':float})\n",
    "    xl_group = xl_df.groupby('interval')\n",
    "\n",
    "    gy_df = pd.DataFrame(gy, columns=cols)\n",
    "    gy_df = gy_df.astype({'x': float, 'y': float, 'z': float, 'timestamp':float})\n",
    "    gy_group = gy_df.groupby('interval')\n",
    "    \n",
    "    common_ids = np.intersect1d(np.array(list(xl_group.groups.keys())), np.array(list(gy_group.groups.keys())))\n",
    "\n",
    "    orientation = []\n",
    "\n",
    "\n",
    "    xl_global = []\n",
    "    prev_q = [1,0,0,0]\n",
    "\n",
    "    xl_w = [] #(3, n, 3) history of 3, n data , xyz \n",
    "    gy_w = []\n",
    "\n",
    "    common_ids = np.intersect1d(np.array(list(xl_group.groups.keys())), np.array(list(gy_group.groups.keys())))\n",
    "\n",
    "    orientation = []\n",
    "    for interval_id in common_ids:\n",
    "        xl_grp = xl_group.get_group(interval_id).copy()\n",
    "\n",
    "        gy_grp = gy_group.get_group(interval_id).copy()\n",
    "\n",
    "        group_ts = [xl_grp.iloc[xl_grp.shape[0]//2]['timestamp'] for _ in range(interval_odr)]\n",
    "        group_interval = [xl_grp.iloc[xl_grp.shape[0]//2]['interval'] for _ in range(interval_odr)]\n",
    "        \n",
    "\n",
    "        xl_1 = preprocess_sensor(xl_grp.drop(columns=['interval']).values)\n",
    "        xl1_clipped = clip_xl(xl_1[:,1:], 2)\n",
    "\n",
    "        gy_1 = preprocess_sensor(gy_grp.drop(columns=['interval']).values) #remove unique values \n",
    "        xl_p, gy_p = preprocess_imu(xl1_clipped, gy_1[:,1:], gyr_offset)\n",
    "\n",
    "\n",
    "        xl_w.append(xl_p.copy())\n",
    "        gy_w.append(gy_p.copy())\n",
    "\n",
    "        if len(xl_w) > 3: \n",
    "            xl_w.pop(0)\n",
    "            gy_w.pop(0)\n",
    "\n",
    "        if len(xl_w) != 3:\n",
    "            continue \n",
    "\n",
    "        xl_t = time_align(xl_w, 1000, interval_odr)\n",
    "        gy_t = time_align(gy_w, 1000, interval_odr)\n",
    "\n",
    "\n",
    "        model = Madgwick(acc=xl_t, gyr=gy_t, dt=1/interval_odr, q0 = [1,0,0,0], gain =.0033 )\n",
    "        \n",
    "        prev_q = model.Q[-1]\n",
    "        interval_q = model.Q\n",
    "\n",
    "        group_xl_ned = []\n",
    "        for q,x in zip(np.array(interval_q), xl_t):\n",
    "           \n",
    "            mag = np.linalg.norm(x)\n",
    "            norm_vec = x / mag\n",
    "\n",
    "            ned_vec_1 = rotate_to_ned(q, norm_vec)\n",
    "            vec1 = np.round(ned_vec_1,4)\n",
    "\n",
    "            assert np.issubdtype(ned_vec_1.dtype, np.floating)\n",
    "            \n",
    "            ned_vec = vec1 * mag\n",
    "            print(ned_vec)\n",
    "            ned_vec[2] -= 9.810665\n",
    "\n",
    "            print(ned_vec, x)\n",
    "            group_xl_ned.append(ned_vec)\n",
    "\n",
    "        assert np.issubdtype(np.array(group_xl_ned).dtype, np.floating)\n",
    "        group_xl_ned = np.column_stack([group_xl_ned, group_ts])\n",
    "        xl_global.extend(group_xl_ned)\n",
    "\n",
    "        yaws, pitches, rolls = quaternion_to_euler(model.Q)\n",
    "        rpy = [rolls, pitches, yaws]\n",
    "        orientation.extend(rpy)\n",
    "        np.array(orientation)\n",
    "\n",
    "    return np.array(xl_global), np.array(orientation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "715a7419",
   "metadata": {},
   "outputs": [],
   "source": [
    "gy_mask_combined = np.logical_and(gy_mask_x, gy_mask_y, gy_mask_z)\n",
    "gy_timestamps = imu_dic[\"Node[1].GY1.timestamp\"]\n",
    "new_gy_ts = gy_timestamps[gy_mask_combined]\n",
    "\n",
    "\n",
    "xl_mask_combined = np.logical_and(mask_x, mask_y, mask_z)\n",
    "timestamps = imu_dic[\"Node[1].XL1.timestamp\"]\n",
    "new_xl_ts = timestamps[xl_mask_combined]\n",
    "\n",
    "print(new_xl_ts.shape)\n",
    "\n",
    "xl_stack = np.array([imu_dic['Node[1].XL1.interval_id'][xl_mask_combined],imu_dic['Node[1].XL1.timestamp'][xl_mask_combined], \n",
    "            imu_dic['Node[1].XL1.X'][xl_mask_combined],imu_dic['Node[1].XL1.Y'][xl_mask_combined],\n",
    "              imu_dic['Node[1].XL1.Z'][xl_mask_combined]]).T\n",
    "\n",
    "gy_stack = np.array([imu_dic['Node[1].GY1.interval_id'][gy_mask_combined],imu_dic['Node[1].GY1.timestamp'][gy_mask_combined], \n",
    "            imu_dic['Node[1].GY1.X'][gy_mask_combined],\n",
    "            imu_dic['Node[1].GY1.Y'][gy_mask_combined], imu_dic['Node[1].GY1.Z'][gy_mask_combined]]).T\n",
    "\n",
    "print(xl_stack.T.shape, gy_stack.T.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b5a68d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "offset_x = np.mean(imu_dic['Node[1].GY1.X'][gy_mask_combined])\n",
    "offset_y = np.mean(imu_dic['Node[1].GY1.Y'][gy_mask_combined])\n",
    "offset_z = np.mean(imu_dic['Node[1].GY1.Z'][gy_mask_combined])\n",
    "\n",
    "offset = np.array([offset_x, offset_y, offset_z])\n",
    "xl_global, orientation = align_timestamps(xl_stack, gy_stack, 1000, offset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f658ae1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def xl_resample(xl,gy, interval_odr):\n",
    "    cols =['interval','timestamp','x', 'y', 'z']\n",
    "\n",
    "    xl_df = pd.DataFrame(xl, columns=cols)\n",
    "    xl_df = xl_df.astype({'x': float, 'y': float, 'z': float, 'timestamp':float})\n",
    "    xl_group = xl_df.groupby('interval')\n",
    "\n",
    "    gy_df = pd.DataFrame(gy, columns=cols)\n",
    "    gy_df = gy_df.astype({'x': float, 'y': float, 'z': float, 'timestamp':float})\n",
    "    gy_group = gy_df.groupby('interval')\n",
    "    \n",
    "    common_ids = np.intersect1d(np.array(list(xl_group.groups.keys())), np.array(list(gy_group.groups.keys())))\n",
    "    xl_resample = []\n",
    "    xl_w = [] #(3, n, 3) history of 3, n data , xyz \n",
    "\n",
    "    common_ids = np.intersect1d(np.array(list(xl_group.groups.keys())), np.array(list(gy_group.groups.keys())))\n",
    "\n",
    "    for interval_id in common_ids:\n",
    "\n",
    "        xl_grp = xl_group.get_group(interval_id).copy()\n",
    "        group_ts = [xl_grp.iloc[xl_grp.shape[0]//2]['timestamp'] for _ in range(interval_odr)]\n",
    "\n",
    "        xl_1 = preprocess_sensor(xl_grp.drop(columns=['interval']).values)\n",
    "        xl1_clipped = clip_xl(xl_1[:,1:], 2)\n",
    "        xl_w.append(xl1_clipped.copy())\n",
    "\n",
    "        xyz_r = resample(xyz_w, num=(interval_odr*3), axis=0)\n",
    "        curr_xyz = xyz_r[1000:2000,:]\n",
    "\n",
    "        curr_dat = np.column_stack([curr_xyz, group_ts])\n",
    "\n",
    "        xl_resample.extend(curr_dat)\n",
    "\n",
    "    return np.array(xl_resample)\n",
    "\n",
    "\n",
    "def compute_aligned_timestamps(xl_data):\n",
    "\n",
    "    xl_df= pd.DataFrame(xl_data, columns=['xl.x','xl.y','xl.z','timestamp'])\n",
    "\n",
    "    new_ts_col = []\n",
    "    xl_dt = 1/1000\n",
    "    for ts in np.unique(xl_df['timestamp'].astype(int)):\n",
    "\n",
    "        curr_ts = ts\n",
    "        for _ in range(1000):\n",
    "            new_ts_col.append(curr_ts)\n",
    "            curr_ts += xl_dt\n",
    "\n",
    "    xl_df['timestamp_aligned'] = new_ts_col\n",
    "    return xl_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76af3f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotation_ned(lat, lon):\n",
    "    R_ned = np.array([[-np.sin(lat)*np.cos(lon), -np.sin(lat)*np.sin(lon), np.cos(lat)],\n",
    "                     [-np.sin(lon), np.cos(lon),0],\n",
    "                     [-np.cos(lat)*np.cos(lon), -np.cos(lat)*np.sin(lon), -np.sin(lat)]])\n",
    "    return R_ned \n",
    "def gps_pos_vel(gps_ned, dt): \n",
    "\n",
    "    vel_ned = gps_ned / dt.values[:, np.newaxis]\n",
    "    acc_ned = np.diff(vel_ned, axis=0) / dt.values[1:, np.newaxis]  \n",
    "    displacement = np.cumsum(gps_ned, axis=0)\n",
    "    return vel_ned, acc_ned, displacement\n",
    "\n",
    "def ecef_to_ned(gps_pos_ref):\n",
    "    deltas = (gps_pos_ref[['Node[1].ECEF.X', 'Node[1].ECEF.Y', 'Node[1].ECEF.Z']].values /1000) - (gps_pos_ref[['Node[1].ECEF.X.ref', 'Node[1].ECEF.Y.ref', 'Node[1].ECEF.Z.ref']].values/1000)   \n",
    "    \n",
    "    #use reference lat and lon points \n",
    "    lons = gps_pos_ref['Node[1].LLH.Lon.ref'] * (np.pi/180) \n",
    "    lats = gps_pos_ref['Node[1].LLH.Lat.ref'] * (np.pi/180)\n",
    "\n",
    "    ned_values = []\n",
    "    mags = []\n",
    "    timestamps = []\n",
    "    for i, (lat, lon) in enumerate(zip(lats, lons)): \n",
    "        rotation_matrix = rotation_ned(lat,lon)\n",
    "        norm = np.linalg.norm(deltas[i,:])\n",
    "        ned_vec = rotation_matrix @ deltas[i,:] / norm\n",
    "        ned_mag = np.linalg.norm(ned_vec)\n",
    "        mags.append(ned_mag )\n",
    "        ned_values.append(ned_vec * norm)\n",
    "        timestamps.append(gps_pos_ref.iloc[i]['timestamp'])\n",
    "    ned_values = np.array(ned_values)\n",
    "    return ned_values, np.array(mags), np.array(timestamps)\n",
    "\n",
    "new_gps = gps_df.copy()\n",
    "new_gps[['Node[1].ECEF.X.ref','Node[1].ECEF.Y.ref', 'Node[1].ECEF.Z.ref',\n",
    "         'Node[1].LLH.Lat.ref','Node[1].LLH.Lon.ref','timestamp_ref']] = new_gps[[\"Node[1].ECEF.X\", \"Node[1].ECEF.Y\",\n",
    "                                                                                  \"Node[1].ECEF.Z\",'Node[1].LLH.Lat',\n",
    "                                                                                  'Node[1].LLH.Lon', 'timestamp']].shift(1)\n",
    "\n",
    "gps_pos_ref = new_gps[[\"Node[1].ECEF.X\", \"Node[1].ECEF.Y\",\n",
    "                       \"Node[1].ECEF.Z\",'Node[1].ECEF.X.ref',\n",
    "                       'Node[1].ECEF.Y.ref', 'Node[1].ECEF.Z.ref',\n",
    "                      'Node[1].LLH.Lat.ref', 'Node[1].LLH.Lon.ref',\n",
    "                      'timestamp','timestamp_ref','interval_id']].dropna()\n",
    "\n",
    "gps_ned, ned_mags, timestamps = ecef_to_ned(gps_pos_ref) \n",
    "print(gps_ned.shape, timestamps.shape)\n",
    "\n",
    "dt = gps_pos_ref['timestamp'] - gps_pos_ref['timestamp_ref']\n",
    "vel_ned, acc_ned, displacement = gps_pos_vel(gps_ned, dt)\n",
    "print(vel_ned.shape, acc_ned.shape, displacement.shape)\n",
    "gps_vel_pos = np.column_stack([vel_ned, displacement, timestamps])\n",
    "\n",
    "gps_vel_pos = pd.DataFrame(gps_vel_pos, columns=['vel.x', 'vel.y', 'vel.z', 'pos.x', 'pos.y', 'pos.z', 'timestamp'])\n",
    "gps_vel_pos.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19425487",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(3, 2, figsize=(12, 10))\n",
    "\n",
    "# Plot velocity (left column)\n",
    "axes[0, 0].plot(gps_vel_pos['vel.x'])\n",
    "axes[0, 0].set_title('Velocity X')\n",
    "\n",
    "axes[1, 0].plot(gps_vel_pos['vel.y'])\n",
    "axes[1, 0].set_title('Velocity Y')\n",
    "\n",
    "axes[2, 0].plot(gps_vel_pos['vel.z'])\n",
    "axes[2, 0].set_title('Velocity Z')\n",
    "\n",
    "# Plot position (right column)\n",
    "axes[0, 1].plot(gps_vel_pos['pos.x'])\n",
    "axes[0, 1].set_title('Position X')\n",
    "\n",
    "axes[1, 1].plot(gps_vel_pos['pos.y'])\n",
    "axes[1, 1].set_title('Position Y')\n",
    "\n",
    "axes[2, 1].plot(gps_vel_pos['pos.z'])\n",
    "axes[2, 1].set_title('Position Z')\n",
    "\n",
    "# Optional: Improve layout\n",
    "for ax in axes.flat:\n",
    "    ax.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e43d4d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_acc(row):\n",
    "    acc = np.sqrt(row['xl.x']**2 + row['xl.y']**2)\n",
    "    if row['xl.x'] < 0 :\n",
    "        acc*=-1\n",
    "\n",
    "    return acc\n",
    "\n",
    "def xl_state_estimate(x_prev, u, F, dt):\n",
    "    x_k = F @ np.array(x_prev) + np.array([(dt**2)/2, dt]) * u \n",
    "    return x_k \n",
    "\n",
    "\n",
    "def Kalman_acc_update(x_prev, P_prev, Q_xl, F, row, imu_dt):\n",
    "\n",
    "    acc = get_acc(row)\n",
    "    x_update = xl_state_estimate(x_prev, acc, F, imu_dt)\n",
    "    P_update = F @ P_prev @ F.T + Q_xl\n",
    "\n",
    "    return x_update, P_update\n",
    "\n",
    "def Kalman_gps_udpate(gps_state, P_prev, x_prev, R_gps):\n",
    "    \n",
    "    K = P_prev @ np.linalg.inv(P_prev + R_gps)\n",
    "    H = np.array([[1, 0], [0, 1]])  #\n",
    "\n",
    "    x_update = x_prev + K @ (gps_state - x_prev)\n",
    "    # P_update = P_prev - K @ Q_gps\n",
    "    # P_update = (np.eye(2) - K @ H) @ P_prev\n",
    "    I = np.eye(2)\n",
    "    P_update = (I - K @ H) @ P_prev @ (I - K @ H).T + K @ R_gps @ K.T\n",
    "\n",
    "    # print(\"GPS UPDATE\", x_update)\n",
    "    return x_update, P_update, K\n",
    "\n",
    "    \n",
    "def test_kalman(xl_global, gps_df, init_x, gps_dt):\n",
    "    \n",
    "    gps_idx = 0 \n",
    "    x_history = [init_x]\n",
    "    P_history = []\n",
    "    gain_history = []\n",
    "\n",
    "    spectral_density_variance = 0.0001 \n",
    "    velocity_random_walk_variance_xy =  0.00001 \n",
    "\n",
    "    for i, row in xl_global.iterrows():\n",
    "\n",
    "        if i == 0:\n",
    "            imu_dt = .001\n",
    "            gps_dt = .2\n",
    "\n",
    "\n",
    "            Q_xl = spectral_density_variance * np.array([\n",
    "                    [imu_dt**4 / 4, imu_dt**3 / 2],\n",
    "                    [imu_dt**3 / 2, imu_dt**2]\n",
    "                ]) + velocity_random_walk_variance_xy * np.array([\n",
    "                    [0, 0],\n",
    "                    [0, 1]\n",
    "                ])\n",
    "\n",
    "            P_history.append(Q_xl)\n",
    "        else: \n",
    "            imu_dt = xl_global.iloc[i]['timestamp_aligned'] - xl_global.iloc[i-1]['timestamp_aligned']\n",
    "            gps_dt = gps_df.iloc[gps_idx]['timestamp'] - gps_df.iloc[gps_idx-1]['timestamp']\n",
    "\n",
    "        F = np.array([[1, imu_dt],[0, 1]]) \n",
    "\n",
    "        \n",
    "        Q_xl = spectral_density_variance * np.array([\n",
    "                [imu_dt**4 / 4, imu_dt**3 / 2],\n",
    "                [imu_dt**3 / 2, imu_dt**2]\n",
    "            ]) + velocity_random_walk_variance_xy * np.array([\n",
    "                [0, 0],\n",
    "                [0, 1]\n",
    "            ])\n",
    "        \n",
    "        gps_vel_var = (0.125 * 10) * gps_dt\n",
    "        gps_pos_var = (gps_vel_var * 10) * gps_dt**2\n",
    "\n",
    "        R_gps = np.array([[gps_pos_var,0],[0, gps_vel_var]]) \n",
    "\n",
    "        xl_ts = row['timestamp_aligned']\n",
    "        match = gps_df[round(gps_df['timestamp'],1) == round(xl_ts,3)]\n",
    "                    \n",
    "        x_k, P_k = Kalman_acc_update(x_history[-1], P_history[-1], Q_xl, F, row, imu_dt)\n",
    "        # print(\"X_K\", x_k)\n",
    "\n",
    "        if not match.empty and xl_ts != 46757790.0:\n",
    "            gps_idx += 1\n",
    "            vel_xyz = match[['vel.x', 'vel.y']]\n",
    "            pos_xyz = match[['pos.x', 'pos.y']]\n",
    "            gps_vel = np.linalg.norm(vel_xyz, axis=1)\n",
    "            gps_pos = np.linalg.norm(pos_xyz, axis=1)\n",
    "            gps_state = np.array([gps_pos[0], gps_vel[0]])\n",
    "            # print(\"GPS STATE,XPREV\",gps_state,  x_history[-1])\n",
    "\n",
    "            x_update, P_update, gain = Kalman_gps_udpate(gps_state, P_k, x_k, R_gps)\n",
    "\n",
    "            x_history.append(x_update)\n",
    "            P_history.append(P_update)\n",
    "            gain_history.append(gain)\n",
    "\n",
    "        else:\n",
    "            x_history.append(x_k)\n",
    "            P_history.append(P_k)\n",
    "\n",
    "        if i == 100000:\n",
    "            break\n",
    "    return np.array(x_history), np.array(P_history), gain_history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce46fe45",
   "metadata": {},
   "outputs": [],
   "source": [
    "inital_pos = 0\n",
    "inital_vel = 0\n",
    "init_x = np.array([inital_pos, inital_vel])\n",
    "centered = xl_static_df[['xl.x', 'xl.y']] - xl_static_df[['xl.x', 'xl.y']].mean()\n",
    "centered['timestamp_aligned'] = xl_static_df['timestamp_aligned']\n",
    "\n",
    "x_history, P_history, gain_history = test_kalman(centered, gps_vel_pos, init_x, gps_dt=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b09bac0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def imu_dead_reckoning(xl_ned, prev_pos, prev_vel, dt):\n",
    "    \n",
    "    velocity = np.empty((len(xl_ned), 3))\n",
    "    position = np.empty((len(xl_ned), 3))\n",
    "\n",
    "    if prev_vel is not None: \n",
    "        velocity[0] = prev_vel\n",
    "    if prev_pos is not None: \n",
    "        position[0] = prev_pos\n",
    "\n",
    "    start_idx = 1 if prev_vel is not None and prev_pos is not None else 0\n",
    "\n",
    "    for t in range(start_idx, len(xl_ned)):\n",
    "        velocity[t] = velocity[t-1] + xl_ned[t-1] * dt\n",
    "        position[t] = position[t-1] + velocity[t] * dt\n",
    "\n",
    "    curr_pos = position[-1,:]\n",
    "    curr_vel = velocity[-1,:]\n",
    "    return np.concatenate([curr_pos, curr_vel])\n",
    "\n",
    "def ewma(xl_global, gps_df, init_x, alpha):\n",
    "\n",
    "    x_history = [init_x]\n",
    "    for i, row in xl_global.iterrows():\n",
    "            \n",
    "        state_prev = x_history[-1]\n",
    "        prev_pos = state_prev[0]\n",
    "        prev_vel = state_prev[1]\n",
    "\n",
    "        # vel_update = prev_vel + (acc * xl_dt)\n",
    "        # pos_update = prev_pos + (vel_update * xl_dt)\n",
    "        \n",
    "        if i != 0: \n",
    "            dt = xl_global.loc[i,'timestamp_aligned'] - xl_global.loc[i - 1,'timestamp_aligned']\n",
    "        else:\n",
    "            dt = 1/1000\n",
    "\n",
    "        xl_ts = row['timestamp_aligned']\n",
    "        match = gps_df[round(gps_df['timestamp'],1) == round(xl_ts,1)]\n",
    "        \n",
    "        if xl_ts > gps_df.iloc[-1]['timestamp']:\n",
    "            print('Exceeded gps timestamps')\n",
    "            break\n",
    "\n",
    "        if not match.empty and i != 0:\n",
    "            vel_xyz = match[['vel.x', 'vel.y', 'vel.z']].values.flatten()\n",
    "            pos_xyz = match[['pos.x', 'pos.y', 'pos.z']].values.flatten()\n",
    "\n",
    "            gps_state = np.concatenate([pos_xyz, vel_xyz])\n",
    "            state_pred = x_history[-1]\n",
    "            # print(i)\n",
    "            # print('state_prev',state_prev)\n",
    "            # print('gps_state',gps_state)\n",
    "            gps_update = state_pred + alpha * (gps_state - state_pred) \n",
    "            # gps_update = (1-alpha) * state_pred + alpha * (gps_state)\n",
    "            # print('gps_update',gps_update)\n",
    "            x_history.append(gps_update)\n",
    "\n",
    "        else:\n",
    "            prev_state = x_history[-1]  \n",
    "            prev_pos = prev_state[:3] \n",
    "            prev_vel = prev_state[3:]\n",
    "            \n",
    "            xl_ned = row[['xl.x','xl.y','xl.z']].values\n",
    "            state_update = imu_dead_reckoning(xl_ned, prev_pos, prev_vel, dt)\n",
    "            x_history.append(state_update)\n",
    "\n",
    "        if i == 30000:\n",
    "            break\n",
    "    return np.array(x_history)\n",
    "\n",
    "def double_ewma(xl_global, gps_df,init_x, alpha):\n",
    "\n",
    "    s_prime_history = [init_x]\n",
    "    s_double_prime_history = [init_x]\n",
    "    x_history = [init_x]\n",
    "\n",
    "    for i,row in xl_global.iterrows():\n",
    "\n",
    "\n",
    "        xl_ts = row['timestamp_aligned']\n",
    "        match = gps_df[round(gps_df['timestamp'],1) == round(xl_ts,3)]\n",
    "\n",
    "        if i != 0: \n",
    "            dt = xl_global.loc[i,'timestamp_aligned'] - xl_global.loc[i - 1,'timestamp_aligned']\n",
    "        else:\n",
    "            dt = 1/1000\n",
    "\n",
    "        if not match.empty and i != 0:\n",
    "\n",
    "            gps_vel = match[['vel.x', 'vel.y', 'vel.z']].values.flatten()\n",
    "            gps_pos = match[['pos.x', 'pos.y', 'pos.z']].values.flatten()\n",
    "            gps_state = np.concatenate([gps_pos, gps_vel])\n",
    "\n",
    "            s_prime_prev = s_prime_history[-1]\n",
    "            s_double_prev = s_double_prime_history[-1]\n",
    "\n",
    "            s_prime_update = (alpha * gps_state) + (1-alpha) * s_prime_prev\n",
    "            s_double_update = (alpha * s_prime_update) + (1-alpha) * s_double_prev\n",
    "            \n",
    "            s_prime_history.append(s_prime_update)\n",
    "            s_double_prime_history.append(s_double_update)\n",
    "\n",
    "            x_history.append((2*s_prime_update) - s_double_update)\n",
    "\n",
    "        else:\n",
    "            prev_state = x_history[-1]  \n",
    "            prev_pos = prev_state[:3] \n",
    "            prev_vel = prev_state[3:]\n",
    "            \n",
    "            xl_ned = row[['xl.x','xl.y','xl.z']].values\n",
    "            state_update = imu_dead_reckoning(xl_ned, prev_pos, prev_vel, dt)\n",
    "            x_history.append(state_update)\n",
    "\n",
    "\n",
    "        if i == 30000:\n",
    "            break\n",
    "    return np.array(x_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b623ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ewma_df = pd.DataFrame(ewma_history, columns=['pos.x','pos.y','pos.z','vel.x','vel.y','vel.z'])\n",
    "fig, axes = plt.subplots(3, 2, figsize=(12, 10))\n",
    "\n",
    "# Plot velocity (left column)\n",
    "axes[0, 0].plot(ewma_df['vel.x'])\n",
    "axes[0, 0].plot(ewma_df['vel.x'].rolling(window=500).mean(), label='Avg')\n",
    "axes[0, 0].set_title('Velocity X')\n",
    "\n",
    "\n",
    "axes[1, 0].plot(ewma_df['vel.y'])\n",
    "axes[1, 0].plot(ewma_df['vel.y'].rolling(window=300).mean(), label='Avg')\n",
    "axes[1, 0].set_title('Velocity Y')\n",
    "\n",
    "axes[2, 0].plot(ewma_df['vel.z'])\n",
    "axes[2, 0].plot(ewma_df['vel.z'].rolling(window=300).mean(), label='Avg')\n",
    "axes[2, 0].set_title('Velocity Z')\n",
    "\n",
    "# Plot position (right column)\n",
    "axes[0, 1].plot(ewma_df['pos.x'])\n",
    "axes[0, 1].plot(ewma_df['pos.x'].rolling(window=300).mean(), label='Avg')\n",
    "axes[0, 1].set_title('Position X')\n",
    "\n",
    "axes[1, 1].plot(ewma_df['pos.y'])\n",
    "axes[1, 1].plot(ewma_df['pos.y'].rolling(window=300).mean(), label='Avg')\n",
    "axes[1, 1].set_title('Position Y')\n",
    "\n",
    "axes[2, 1].plot(ewma_df['pos.z'])\n",
    "axes[2, 1].plot(ewma_df['pos.z'].rolling(window=300).mean(), label='Avg')\n",
    "axes[2, 1].set_title('Position Z')\n",
    "\n",
    "# Optional: Improve layout\n",
    "for ax in axes.flat:\n",
    "    ax.grid(True)\n",
    "    ax.legend()\n",
    "\n",
    "fig.suptitle('Fusion IMU + GPS EWMA')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
